{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MindSpore version:  2.1.0\n",
      "The result of multiplication calculation is correct, MindSpore has been installed on platform [Ascend] successfully!\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "# mindspore.set_context(device_target='CPU')\n",
    "# mindspore.set_context(device_target='GPU')\n",
    "mindspore.set_context(device_target=\"Ascend\")\n",
    "mindspore.set_context(device_id=0)\n",
    "mindspore.run_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 微调\n",
    "\n",
    "微调（Fine-tuning）是指在预训练模型的基础上，针对特定任务进行额外训练的过程。通过微调，我们可以使预训练模型适应特定领域的任务，提高模型在这些任务上的表现，而无需从头开始训练一个新模型。\n",
    "\n",
    "<img src=\"./images_llm/fig6.1.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 分类微调\n",
    "\n",
    "在大语言模型领域，最常见的微调方法是指令微调和分类微调。\n",
    "\n",
    "指令微调（Instruction Fine-tuning）是通过一组任务，使用特定指令来训练语言模型，从而提高其理解和执行自然语言提示中所描述任务的能力。这种方法使模型能够理解并执行用户以指令形式提出的各种任务。\n",
    "\n",
    "<img src=\"./images_llm/fig6.2.svg\" width=\"600\">\n",
    "\n",
    "分类微调（Classification Fine-tuning）是将预训练语言模型针对具体分类任务进行调整的过程。通过添加一个分类头（通常是一个简单的线性层），并使用带有标签的训练数据，模型学习将文本映射到特定类别。\n",
    "\n",
    "<img src=\"./images_llm/fig6.3.svg\" width=\"500\">\n",
    "\n",
    "在本章中，我们将重点关注分类微调，并演示如何将预训练的大语言模型微调为一个垃圾邮件分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 数据准备\n",
    "\n",
    "\n",
    "数据准备是微调过程中的关键步骤。我们需要收集、整理和预处理适合目标任务的数据，以便模型能够有效学习。\n",
    "\n",
    "<img src=\"./images_llm/fig6.4.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:05.140382Z",
     "start_time": "2025-02-10T10:29:05.120299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:07.246954Z",
     "start_time": "2025-02-10T10:29:05.151454Z"
    }
   },
   "outputs": [],
   "source": [
    "#! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:07.905904Z",
     "start_time": "2025-02-10T10:29:07.437678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，该数据集包含了5,572条短信记录，每条记录都被标记为\"ham\"（正常短信）或\"spam\"（垃圾短信）。我们首先检查一下两个类别的分布情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:07.983091Z",
     "start_time": "2025-02-10T10:29:07.969474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集中存在类别不平衡的问题，\"ham\"类别有4,825条记录，而\"spam\"类别只有747条记录。为了避免模型偏向多数类别，我们需要对数据集进行欠采样处理，确保每个类别均包含747个实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:08.265050Z",
     "start_time": "2025-02-10T10:29:08.238651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam    747\n",
      "ham     747\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将字符串标签\"ham\"和\"spam\"转换为整数标签 0 和 1，这样更适合机器学习模型处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:08.577371Z",
     "start_time": "2025-02-10T10:29:08.555170Z"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:08.625078Z",
     "start_time": "2025-02-10T10:29:08.612076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们创建一个 random_split 函数将数据集分成三部分：70％用于训练，10％用于验证，20％用于测试。这样的划分可以确保我们有足够的数据来训练模型，同时保留一部分数据用于验证模型表现和最终测试评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:08.735141Z",
     "start_time": "2025-02-10T10:29:08.704033Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 数据加载器\n",
    "\n",
    "在处理文本数据时，我们面临一个常见的挑战：文本长度不一致。为了能够高效地进行批处理，我们需要统一每个批次中文本的长度。\n",
    "\n",
    "我们当前处理的文本消息长度各不相同。要像处理固定大小的文本块那样对这些消息进行批处理，我们有两种选择：\n",
    "\n",
    "- 将所有消息截断为数据集或批次中最短消息的长度。\n",
    "- 将所有消息填充为数据集或批次中最长消息的长度。\n",
    "\n",
    "第一种方案操作相对简单，但缺点是可能会丢失较长消息中的部分信息，因为截断操作会把超过最短长度的部分直接删除。因此，我们倾向于选择第二种方案，即保留消息的全部内容，以确保信息的完整性。第二种方案需要为较短的消息添加填充标记。这里使用的填充标记是 \"<|endoftext|>\"。\n",
    "\n",
    "<img src=\"./images_llm/fig6.5.svg\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先检查这个标记在GPT-2词汇表中的ID："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:09.677583Z",
     "start_time": "2025-02-10T10:29:08.991898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Keyword arguments {'allowed_special': {'<|endoftext|>'}} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "# 指定本地词汇表文件所在的目录路径\n",
    "local_path = \"./gpt2-tokenizer\"\n",
    "\n",
    "# 从本地路径加载GPT - 2分词器\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(local_path)\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们基于上述概念定义SpamDataset类。该类的关键职责包括：识别训练数据集中最长的序列、对文本消息进行编码、对序列进行填充，确保所有输入数据都具有相同的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:11.583411Z",
     "start_time": "2025-02-10T10:29:09.683600Z"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "from mindspore import Tensor\n",
    "\n",
    "class SpamDataset:\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            # Tensor(encoded, dtype=mindspore.int64),\n",
    "            # Tensor(label, dtype=mindspore.int64)\n",
    "            encoded, label\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建训练数据集实例，并获取数据集中最长序列的长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:11.646015Z",
     "start_time": "2025-02-10T10:29:11.600944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们对验证集和测试集进行填充，使其长度与最长训练序列保持一致：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:11.709073Z",
     "start_time": "2025-02-10T10:29:11.663944Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果设定批大小为8，那么每个批次将包含8个长度为120的训练样本，以及每个样本对应的类标签（0表示正常短信，1表示垃圾短信）。\n",
    "\n",
    "\n",
    "<img src=\"./images_llm/fig6.6.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:11.740030Z",
     "start_time": "2025-02-10T10:29:11.725907Z"
    }
   },
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "mindspore.set_seed(123)\n",
    "\n",
    "train_loader = GeneratorDataset(train_dataset, [\"input_ids\", \"target_ids\"], shuffle=True)\n",
    "train_loader = train_loader.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "val_loader = GeneratorDataset(val_dataset, [\"input_ids\", \"target_ids\"], shuffle=True)\n",
    "val_loader = val_loader.batch(batch_size, drop_remainder=False)\n",
    "\n",
    "test_loader = GeneratorDataset(test_dataset, [\"input_ids\", \"target_ids\"], shuffle=True)\n",
    "test_loader = test_loader.batch(batch_size, drop_remainder=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码创建了训练集、验证集和测试集的数据加载器，并以每批8个样本的形式加载文本消息及其对应的标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:11.977327Z",
     "start_time": "2025-02-10T10:29:11.757210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: (8, 120)\n",
      "Label batch dimensions (8,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:12.008902Z",
     "start_time": "2025-02-10T10:29:11.995318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 使用预训练权重初始化模型\n",
    "\n",
    "分类微调的一个关键优势是能够利用预训练模型已经学到的知识。我们将使用预训练的GPT-2模型作为起点，并在此基础上进行垃圾邮件分类任务的微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images_llm/fig6.7.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们定义模型的配置参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:12.040967Z",
     "start_time": "2025-02-10T10:29:12.025833Z"
    }
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们下载并加载预训练的GPT-2权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:28.543600Z",
     "start_time": "2025-02-10T10:29:12.058958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(215213:281473029364592,MainProcess):2025-03-13-20:08:09.427.058 [mindspore/nn/layer/basic.py:171] This parameter `dtype` will be deleted or invisible in the future. Please don't use it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel<\n",
       "  (tok_emb): Embedding<vocab_size=50257, embedding_size=768, use_one_hot=False, embedding_table=Parameter (name=embedding_table, shape=(50257, 768), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "  (pos_emb): Embedding<vocab_size=1024, embedding_size=768, use_one_hot=False, embedding_table=Parameter (name=embedding_table, shape=(1024, 768), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "  (drop_emb): Dropout<p=0.0>\n",
       "  (trf_blocks): SequentialCell<\n",
       "    (0): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (1): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (2): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (3): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (4): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (5): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (6): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (7): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (8): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (9): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (10): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (11): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    >\n",
       "  (final_norm): LayerNorm<>\n",
       "  (out_head): Dense<input_channels=768, output_channels=50257>\n",
       "  >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.set_train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "复用先前章节定义的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import mindspore.numpy as np\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        # with mindspore.context.grad_off():\n",
    "        logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        softmax = ops.Softmax(axis=-1)\n",
    "        probas = softmax(logits)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = ops.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = ops.concat((idx, idx_next), axis=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = Tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "     # 检查是否有批量维度，如果有则移除\n",
    "    if len(token_ids.shape) > 1 and token_ids.shape[0] == 1:\n",
    "        flat = token_ids.squeeze(0)\n",
    "    else:\n",
    "        flat = token_ids\n",
    "    # flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型权重加载到 GPTModel，以确保模型生成连贯的文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:29:39.250344Z",
     "start_time": "2025-02-10T10:29:28.577550Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'allowed_special': {'<|endoftext|>'}} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们测试一下模型是否能够区分垃圾邮件和正常邮件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:15.956292Z",
     "start_time": "2025-02-10T10:29:39.283547Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'allowed_special': {'<|endoftext|>'}} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从输出结果来看，模型在遵循指令方面存在困难。这是因为模型没有进行过指令微调，无法理解并执行特定的指令任务。这也正是我们需要进行分类微调的原因，通过微调使模型能够执行垃圾邮件分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 添加分类头\n",
    "\n",
    "为了对预训练的LLM进行分类微调，我们需要对模型结构进行修改。具体来说，我们将原始的输出层（用于预测下一个词元的概率分布）替换为一个更小的输出层，这个输出层仅映射到两个类别：0（正常短信）和1（垃圾短信）。\n",
    "\n",
    "<img src=\"./images_llm/fig6.8.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先通过 print(model) 打印未经修改的模型架构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:16.003726Z",
     "start_time": "2025-02-10T10:30:15.991294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel<\n",
      "  (tok_emb): Embedding<vocab_size=50257, embedding_size=768, use_one_hot=False, embedding_table=Parameter (name=tok_emb.embedding_table, shape=(50257, 768), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
      "  (pos_emb): Embedding<vocab_size=1024, embedding_size=768, use_one_hot=False, embedding_table=Parameter (name=pos_emb.embedding_table, shape=(1024, 768), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
      "  (drop_emb): Dropout<p=0.0>\n",
      "  (trf_blocks): SequentialCell<\n",
      "    (0): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (1): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (2): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (3): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (4): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (5): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (6): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (7): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (8): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (9): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (10): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    (11): TransformerBlock<\n",
      "      (att): MultiHeadAttention<\n",
      "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
      "        (dropout): Dropout<p=0.0>\n",
      "        >\n",
      "      (ff): FeedForward<\n",
      "        (layers): SequentialCell<\n",
      "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
      "          (1): GELU<>\n",
      "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
      "          >\n",
      "        >\n",
      "      (norm1): LayerNorm<>\n",
      "      (norm2): LayerNorm<>\n",
      "      (drop_shortcut): Dropout<p=0.0>\n",
      "      >\n",
      "    >\n",
      "  (final_norm): LayerNorm<>\n",
      "  (out_head): Dense<input_channels=768, output_channels=50257>\n",
      "  >\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了让模型做好分类微调的准备，我们首先冻结模型，确保所有层都处于不可训练状态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:16.050009Z",
     "start_time": "2025-02-10T10:30:16.037726Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.trainable_params():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "替换输出层（model.out_head），将其改为一个具有两个输出单元的线性层，分别对应\"正常短信\"和\"垃圾短信\"两个类别："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:16.127937Z",
     "start_time": "2025-02-10T10:30:16.113708Z"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "mindspore.set_seed(456)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = nn.Dense(in_channels=BASE_CONFIG[\"emb_dim\"], out_channels=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新添加的`model.out_head`输出层，其`require_grad`属性默认设置为`True`，意味着在训练过程中，它是模型中唯一会自动更新的层。理论上，仅训练这个新添加的输出层就足够了。然而，通过实验发现，微调额外的层能显著提升模型的预测性能。因此，我们把最后一个`Transformer`块以及连接该块到输出层的最后一个`LayerNorm`模块都设置为可训练状态。\n",
    "\n",
    "<img src=\"./images_llm/fig6.9.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:16.143518Z",
     "start_time": "2025-02-10T10:30:16.134143Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].trainable_params():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.trainable_params():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:16.190457Z",
     "start_time": "2025-02-10T10:30:16.177314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[5211  345  423  640]]\n",
      "Inputs dimensions: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = Tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:16.578151Z",
     "start_time": "2025-02-10T10:30:16.222987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " [[[ 3.1096196  0.5925137]\n",
      "  [10.461748   4.008141 ]\n",
      "  [ 7.6329713  3.6736956]\n",
      "  [ 7.2209086  2.8772314]]]\n",
      "Outputs dimensions: (1, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们替换了模型的输出层，因此每个输出的嵌入维度（列数）是 2。我们的目标是微调此模型，使其返回一个类标签，以指示模型输入是“垃圾邮件”还是“正常邮件”。在这个过程中，我们无需微调所有四个输出行；只需专注于单个输出标记。具体来说，我们将重点关注与最后一个输出词元相对应的最后一行。\n",
    "\n",
    "<img src=\"./images_llm/fig6.10.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:30:16.624209Z",
     "start_time": "2025-02-10T10:30:16.610773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: [[7.2209086 2.8772314]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之前的章节中，我们已经深入探讨了注意力机制，它能够在每个输入词元和其他所有输入词元之间建立关系。自注意力机制中使用的因果掩码（causal mask）将词元的注意力范围限制在其当前位置及之前的位置，从而确保每个词元只能受到其自身以及前面词元的影响，如图所示。\n",
    "\n",
    "<img src=\"./images_llm/fig6.11.svg\">\n",
    "\n",
    "根据图中展示的因果注意掩码配置，序列中的最后一个词元积累了最丰富的信息，因为它是唯一可以访问并整合所有先前词元数据的词元。因此，我们使用最后一个词元的输出作为分类决策的依据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 计算分类损失和准确率\n",
    "\n",
    "为了训练和评估我们的分类模型，我们需要定义适当的损失函数和评估指标。\n",
    "\n",
    "用于训练分类模型的损失函数通常是交叉熵损失，它衡量预测分布与真实分布之间的距离。而评估分类性能的常用指标是准确率，它反映了模型正确预测的比例。\n",
    "\n",
    "<img src=\"./images_llm/fig6.12.svg\" width=\"600\">\n",
    "\n",
    "首先，我们来简要讨论一下如何将模型输出转换为类标签预测。\n",
    "\n",
    "<img src=\"./images_llm/fig6.13.svg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:31:09.776336Z",
     "start_time": "2025-02-10T10:31:09.762960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: [[7.2209086 2.8772314]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用softmax函数将输出logits转换为概率分布，然后通过 argmax 函数返回最高概率的位置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:31:09.823083Z",
     "start_time": "2025-02-10T10:31:09.809084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 0\n"
     ]
    }
   ],
   "source": [
    "import mindspore.ops as ops\n",
    "softmax = nn.Softmax(axis=-1)\n",
    "probas = softmax(outputs[:, -1, :])\n",
    "label = ops.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:31:09.869082Z",
     "start_time": "2025-02-10T10:31:09.855085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 0\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = ops.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义calc_accuracy_loader函数来计算正确预测的比例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:35:29.627316Z",
     "start_time": "2025-02-10T10:35:29.613316Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, num_batches=None):\n",
    "    model.set_train(False)\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            # print(logits)\n",
    "            predicted_labels = ops.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return float(correct_predictions) / float(num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:44:34.202097Z",
     "start_time": "2025-02-10T10:35:31.904792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  accuracy: 47.5000%\n",
      "Validation accuracy: 45.0000%\n",
      "Test accuracy: 47.5000%\n"
     ]
    }
   ],
   "source": [
    "mindspore.set_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, num_batches=10)\n",
    "\n",
    "print(f\"Training  accuracy: {train_accuracy*100:.4f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.4f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们为损失计算定义一个辅助函数calc_loss_batch："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:45:31.412536Z",
     "start_time": "2025-02-10T10:45:31.393352Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model):\n",
    "    output = model(input_batch)\n",
    "    # print(\"output:\", output)\n",
    "    logits = output[:, -1, :]  # Logits of last output token\n",
    "    # print(\"logits\", logits)\n",
    "    loss = ops.cross_entropy(logits, target_batch)\n",
    "    # print(\"loss\", loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了计算所有批次的损失，定义 `calc_loss_loader` 函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:45:42.774289Z",
     "start_time": "2025-02-10T10:45:42.759705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, num_batches=None):\n",
    "    model.set_train(False)\n",
    "    total_loss = 0.\n",
    "    # print(len(data_loader))\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model)\n",
    "            # print(loss)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们来计算训练集、验证集以及测试集上的初始损失："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:50:18.212264Z",
     "start_time": "2025-02-10T10:45:44.912322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.301\n",
      "Validation loss: 2.073\n",
      "Test loss: 2.183\n"
     ]
    }
   ],
   "source": [
    "train_loss = calc_loss_loader(train_loader, model, num_batches=5)\n",
    "val_loss = calc_loss_loader(val_loader, model, num_batches=5)\n",
    "test_loss = calc_loss_loader(test_loader, model, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss.asnumpy():.3f}\")\n",
    "print(f\"Validation loss: {val_loss.asnumpy():.3f}\")\n",
    "print(f\"Test loss: {test_loss.asnumpy():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 在监督数据上微调模型\n",
    "\n",
    "接下来，我们需要定义训练函数`train_classifier_simple`来微调预训练的 LLM 以提高垃圾邮件分类的准确率。\n",
    "\n",
    "<img src=\"./images_llm/fig6.14.svg\">\n",
    "\n",
    "这个训练函数的实现理念与用于预训练模型的 `train_model_simple` 函数相似，但有两个主要区别：\n",
    "\n",
    "1. 当前追踪的是训练示例数量（examples_seen）而不是词元数量\n",
    "2. 每个训练周期结束后计算准确率而不是打印生成的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:52:01.722557Z",
     "start_time": "2025-02-10T10:52:01.708587Z"
    }
   },
   "outputs": [],
   "source": [
    "from mindspore import value_and_grad\n",
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.set_train(True)  # Set model to training mode\n",
    "        # 定义前向传播函数\n",
    "        def forward_fn(input_batch, target_batch):\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model)\n",
    "            return loss\n",
    "        # 获取计算梯度的函数\n",
    "        grad_fn = value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            # loss = calc_loss_batch(input_batch, target_batch, model)\n",
    "            # loss.backward() # Calculate loss gradients\n",
    "            # optimizer.step() # Update model weights using loss gradients\n",
    "            #\n",
    "            # 计算损失和梯度\n",
    "            loss, grads = grad_fn(input_batch, target_batch)\n",
    "            # 使用优化器更新参数\n",
    "            optimizer(grads)\n",
    "\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss.asnumpy():.3f}, Val loss {val_loss.asnumpy():.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:52:03.654472Z",
     "start_time": "2025-02-10T10:52:03.642178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, eval_iter):\n",
    "    model.set_train(False)\n",
    "    train_loss = calc_loss_loader(train_loader, model, num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, num_batches=eval_iter)\n",
    "    model.set_train(True)\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将初始化优化器，设置训练周期，并调用train_classifier_simple函数开始训练。我们选择了AdamW优化器，该优化器在Adam的基础上增加了权重衰减正则化，有助于减少过拟合风险。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-10T10:52:06.468630Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.206, Val loss 1.987\n",
      "Ep 1 (Step 000050): Train loss 0.669, Val loss 0.657\n",
      "Ep 1 (Step 000100): Train loss 0.658, Val loss 0.659\n",
      "Training accuracy: 77.50% | Validation accuracy: 85.00%\n",
      "Ep 2 (Step 000150): Train loss 0.643, Val loss 0.633\n",
      "Ep 2 (Step 000200): Train loss 0.640, Val loss 0.610\n",
      "Ep 2 (Step 000250): Train loss 0.625, Val loss 0.600\n",
      "Training accuracy: 85.00% | Validation accuracy: 87.50%\n",
      "Ep 3 (Step 000300): Train loss 0.649, Val loss 0.598\n",
      "Ep 3 (Step 000350): Train loss 0.614, Val loss 0.578\n",
      "Training accuracy: 85.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.604, Val loss 0.573\n",
      "Ep 4 (Step 000450): Train loss 0.598, Val loss 0.564\n",
      "Ep 4 (Step 000500): Train loss 0.596, Val loss 0.569\n",
      "Training accuracy: 85.00% | Validation accuracy: 95.00%\n",
      "Ep 5 (Step 000550): Train loss 0.596, Val loss 0.545\n",
      "Ep 5 (Step 000600): Train loss 0.588, Val loss 0.538\n",
      "Training accuracy: 85.00% | Validation accuracy: 95.00%\n",
      "Training completed in 18.17 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mindspore.set_seed(123)\n",
    "\n",
    "optimizer = nn.AdamWeightDecay(model.trainable_params(), learning_rate=5e-5, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = ops.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = ops.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = ops.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = ops.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码，以计算微调后的LLM在训练集、验证集和测试集上的准确率:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 85.29%\n",
      "Validation accuracy: 88.59%\n",
      "Test accuracy: 85.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 使用LLM实现垃圾邮件分类器\n",
    "\n",
    "现在，我们已经成功地将预训练的LLM微调为一个垃圾邮件分类器。接下来，我们将定义一个函数来使用这个分类器对新的文本进行分类。\n",
    "\n",
    "<img src=\"./images_llm/fig6.15.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下定义的 classify_review 函数与之前 SpamDataset 类中使用的数据预处理步骤类似。该函数将文本分词处理为词元ID后，使用微调后的模型预测得到一个类别标签，并返回相应的类名（\"spam\"或\"not spam\"）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, max_length=None, pad_token_id=50256):\n",
    "    model.set_train(False)\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.embedding_table.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = mindspore.Tensor(input_ids).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    \n",
    "    logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = ops.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们测试一下这个分类器在实际文本上的表现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123\"\n",
    ")\n",
    "\n",
    "print(classify_review(\\\n",
    "    text_1, model, tokenizer, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们将微调好的模型保存到文件中，以便将来使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindspore.save_checkpoint(model, \"review_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(215213:281473029364592,MainProcess):2025-03-13-20:46:18.714.200 [mindspore/nn/layer/basic.py:171] This parameter `dtype` will be deleted or invisible in the future. Please don't use it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel<\n",
       "  (tok_emb): Embedding<vocab_size=50257, embedding_size=768, use_one_hot=False, embedding_table=Parameter (name=tok_emb.embedding_table, shape=(50257, 768), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "  (pos_emb): Embedding<vocab_size=1024, embedding_size=768, use_one_hot=False, embedding_table=Parameter (name=pos_emb.embedding_table, shape=(1024, 768), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "  (drop_emb): Dropout<p=0.0>\n",
       "  (trf_blocks): SequentialCell<\n",
       "    (0): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (1): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (2): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (3): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (4): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (5): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (6): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (7): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (8): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (9): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (10): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    (11): TransformerBlock<\n",
       "      (att): MultiHeadAttention<\n",
       "        (W_query): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_key): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (W_value): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (out_proj): Dense<input_channels=768, output_channels=768, has_bias=True>\n",
       "        (dropout): Dropout<p=0.0>\n",
       "        >\n",
       "      (ff): FeedForward<\n",
       "        (layers): SequentialCell<\n",
       "          (0): Dense<input_channels=768, output_channels=3072, has_bias=True>\n",
       "          (1): GELU<>\n",
       "          (2): Dense<input_channels=3072, output_channels=768, has_bias=True>\n",
       "          >\n",
       "        >\n",
       "      (norm1): LayerNorm<>\n",
       "      (norm2): LayerNorm<>\n",
       "      (drop_shortcut): Dropout<p=0.0>\n",
       "      >\n",
       "    >\n",
       "  (final_norm): LayerNorm<>\n",
       "  (out_head): Dense<input_channels=768, output_channels=2, has_bias=True>\n",
       "  >"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "import mindspore.nn as nn\n",
    "mindspore.set_seed(456)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = nn.Dense(in_channels=BASE_CONFIG[\"emb_dim\"], out_channels=num_classes)\n",
    "\n",
    "\n",
    "param_dict = mindspore.load_checkpoint(\"review_classifier.ckpt\")\n",
    "param_not_load, _ = mindspore.load_param_into_net(model, param_dict)\n",
    "print(param_not_load) # param_not_load是未被加载的参数列表，为空时代表所有参数均加载成功。\n",
    "model.set_train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9 总结\n",
    "\n",
    "在本章中，我们学习了如何对预训练的大语言模型进行分类微调，使其能够执行垃圾邮件分类任务。我们的主要工作包括：\n",
    "\n",
    "1. 数据准备：下载SMS垃圾邮件数据集，进行预处理和平衡处理，并将数据集分为训练集、验证集和测试集。\n",
    "2. 数据加载：创建自定义的SpamDataset类，处理不同长度的文本序列，并使用填充统一序列长度。\n",
    "3. 模型修改：加载预训练的GPT-2模型，冻结大部分参数，并添加一个分类头用于二分类任务。\n",
    "4. 微调训练：定义损失函数和评估指标，使用AdamW优化器对模型进行训练，并监控训练和验证性能。\n",
    "5. 模型部署：创建一个简单的分类函数，将微调后的模型应用于新的文本，实现垃圾邮件检测。\n",
    "\n",
    "微调是一种强大的技术，它允许我们利用预训练模型的知识，使用相对较少的数据和计算资源来解决特定任务。通过本章的学习，我们看到了如何将通用的语言模型转变为专门的文本分类工具，这种方法可以扩展到许多其他自然语言处理任务，如情感分析、主题分类、意图识别等。\n",
    "\n",
    "在下一章中，我们将探索更多的微调技术和应用场景，进一步挖掘大语言模型的潜力。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.15.0",
   "language": "python",
   "name": "tensorflow-1.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
